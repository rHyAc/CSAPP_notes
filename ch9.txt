1. the address translation hardware reads the page table each time it converts a virtual address to a physical address. 
   The operating system is responsible for maintaining the contents of the page table and transferring pages 
   back and forth between disk and DRAM (if missing, MMU triggers an exception, which transfers control in the CPU to 
   a page fault exception handler in the operating system kernel)

2. the strategy of waiting until the last moment to swap in a page, when a miss occurs, is known as demand paging 
   that is used in modern systems but not page prefetching
   
3. programs will tend to work on a smaller set of active pages known as the working set or resident set

4. permission bits can be added to each page table entry (PTE)

5. MMU is typicallly located in core, but memory controller is shared by all cores

Multi-level page tables
	1. only the level 1 table needs to be in main memory at all times
	2. each virtual page number (VPN) i, 1 ≤ i ≤ k, is an index into a page table at level i. 
	3. each PTE in a level k table contains either the physical page number (PPN) of some physical page 
	   or the address of a disk block
	4. TLB caches PTEs from the page tables at the different levels

Linux VM
	1. kernel maintains a distinct task structure ( task_struct in the source code) for each process in
	   the system
	2. one of the entries (mm) in the task structure points to an mm_struct that characterizes the current state of 
	   the virtual memory
	3. pgd, a field in mm_struct pointing to the base of the level 1 table (the page global directory), storesed
	   in the page-directory base address register (PDBR)/the CR3 control register.
	4. mmap , another field in points, points to a list of vm_area_structs, each of which characterizes an area (segment)
	   of the current virtual address space, containing the fields:
	   	1. vm_start, points to the beginning of the area
		2. vm_end, points to the end of the area
		3. vm_prot, describes the read/write permissions for all of the pages contained in the area
		4. vm_flags, describes (among other things) whether the pages in the area are shared with 
		   other processes or private to this process
		5. vm_next, points to the next area struct in the list.

Page fault exception handling
	1. examine legality of the virtual address, by comparing it with the vm_start and vm_end in each area struct
	   (segmentation fault if illegal)
	2. examine legality of access (readable, writable, executable, kernel privilaged) 
	   (a protection exception if illegal)
	3. selecting a victim page, swapping out the victim page if it is dirty, swapping in the new page, 
	   and updating the page table
	4. the CPU restarts the faulting instruction

Memory mapping
	1. initialization
		memory mapping, virtual memory areas are associated with two types of objects on disk
			1. regular disk file
			2. anonymous file
				created by the kernel, contains all binary zeros. When paging in, the kernel 
				overwrites the victim page with binary zeros without transfering data from
				disk to memory. pages in areas that are mapped to anonymous files are sometimes
				called demand-zero pages (bss, heap, stack)
	2. virtual pages are swapped back and forth between a special swap file (wap space, swap area)maintained 
	   by the kernel. The swap space bounds the total amount of virtual pages that can be allocated by the 
	   currently running processes (it means the total amount of virtual memory allocated by all of the
	   processes in a system is limited by the amount of swap space on disk)
	   
	3. processes can map the same object as a private object into their virtual memories sharing the same
	   physical copy of the object.
	4. copy-on-write (used by private objects)
	   	for each process that maps the private object, the page table entries for the corresponding 
		private area are flagged as read-only, and the area struct is flagged as private copyon-write. 
		So long as neither process attempts to write to its respective private area, they continue to
		share a single copy of the object in physical memory. However, as soon as a process attempts to 
		write to some page in the private area, the write triggers a protection fault.When the fault handler
		notices that the protection exception was caused by the process trying to write to a page in a private 
		copy-onwrite area, it creates a new copy of the page in physical memory, updates the page table entry 
		to point to the new copy, and then restores write permissions to the page. When the fault handler 
		returns, the CPU re-executes the write
		
	
	#include <sys/mman.h>
	
	/* the mmap function asks the kernel to create a new virtual memory area to map a contiguous chunk 
	   of the object
	   	args
			starts, a hint at the starting address in virtual memory for the mapping
			length, length bytes
			prot, contains bits describe the access permissions 
				PROT_EXEC, pages in the area consist of instructions that may be executed by the CPU
				PROT_READ, pages in the area may be read.
				PROT_WRITE, pages in the area may be written.
				PROT_NONE, pages in the area cannot be accessed.
			flags, consists of bits that describe the type of the mapped object
				MAP_ANON, anonymous object
				MAP_PRIVATE, private copy-on-write object
				MAP_SHARED, shared object
			offset, offset bytes from the beginning of the file
		returns: pointer to mapped area if OK, MAP_FAILED (–1) on error
	*/
	void *mmap(void * start, size_t length, int prot, int flags, int fd, off_t offset);
	
	/* returns: 0 if OK, –1 on error */
	int munmap(void * start, size_t length);

Dynamic memory allocation
	#include <stdlib.h>
	
	/* return: pointer to allocated block if OK, NULL on error and sets errno
	   NOTICE: in 32-bit mode, malloc returns a block whose address is always a multiple of 8. In 64-bit mode, 
		   the address is always a multiple of 16
	*/
	void * malloc(size_t size);
	
	/* NOTICE: don't refer to the free pointer */
	void free(void * ptr)
	
	
	#include <unistd.h>
	
	/* grows and shrink heap by adding incr to the kernel's brk pointer
		returns: old brk pointer on success, –1 on error and sets errno to ENOMEM
	*/
	void * sbrk(intptr_t incr);

	
	free block organization
		1. implicit free lists
			1. the free blocks are linked implicitly by the size fields in the headers which encodes
			   the block size and whether the block is allocated or free 
			  
			2. simple but the cost of any operation that requires a search of the free list, such as placing 
			   allocated blocks, will be linear in the total number of allocated and free blocks in the heap
		
		2. explicit free lists
			1. organize the free blocks into some form of explicit data structure, such as including a pred
			   (predecessor) and succ (successor) pointer in each implicit free block
			2. thus, free blocks must be large enough to contain all of the necessary pointers which results 
			   in a larger minimum block size
			
			2. maintain the list in last-in first-out (LIFO) order by inserting newly free blocks at the
			   beginning of the list makes freeing a block and coalescing be performed in constant time
			3. maintain the list in address order makes freeing a block require a linear-time search
			   to locate the appropriate predecessor and addressordered first fit enjoys better memory 
			   utilization than LIFO-ordered first fit in which most recently used blocks first are inspected
			   first
		
		3. segregated free lists
			maintain multiple free lists, where each list holds blocks that are roughly the same size by
			partitioning the set of all possible block sizes into equivalence classes called size classes,
			ordering them by increasing size
			   
			1. simple segregated storage
				
			2. segregated fits
		
	allocated block placement policy
		1. first fit
			1. searche the free list from the beginning and chooses the first free block that fits
			
			2. tend to retain large free blocks at the end of the list
			3. but tend to leave "splinters" of small free blocks toward the beginning of the list, 
			   which will increase the search time for larger blocks
		2. next fit
			1. the free list from where the previous search left off
			
			2. run significantly faster than first fit, especially if the front of the list becomes 
			   littered with many small splinters
			3. next fit suffers from worse memory utilization than first fit
		3. best fit
			1. examines every free block and chooses the free block with the smallest size that fits
			
			2. enjoy better memory utilization than either first fit or next fit
			3. require an exhaustive search of the heap with simple free list organizations 
			   such as the implicit free list

	coalescing policy
		1. immediate coalescing
			1. performed in constant time 
			2. thrashing where a block is repeatedly coalesced and then split soon thereafter
		2. deferred coalescing (until some allocation request fails)
			1. need to scan the entire heap, coalescing all free blocks
			2. opted for by fast allocators typically
		
		3. boundary tags
			1. with an implicit free list, can coalesce the next free block in constant time
			2. to the previous one, it needs to search the entire list, remembering the location of 
			   the previous block, until we reached the current block
			   
			3.  boundary tags, set a footer (replica of the header) at the end of each block, can
			    avoid the issue. The optimized approach to increase memory utilization is to store the
			    allocated/free bit of the previous block in current block, then allocated blocks 
			    would not need footers (free blocks would still need)
	
		NOTICE: prologue block (the start of the list) and epilogue blocks (the start of the list) always
			marked as allocated are tricks that eliminate the edge conditions during coalescing
		
	NOTICE: when there is no sufficiently large block for allocating after coalescing, allocator will asks the 
	        kernel for additional heap memory by calling the sbrk function
